---
layout: post
title: "Day 22"
date: 2025-06-25
author: Christian Olabisi
permalink: /day22.html
tags: ["Code Implementation",]

what_i_learned: |
  I learned that my  SVM achieving 86.35% means the  ResNet18Denoise is producing quality separable features from the images in the dataset. This means it's good enough that the  SVM can classify them very effectively, but since there is a 14.47% accuracy in the clean accuracy. The classifier head is not being  properly trained. I just looked over my code and it's because I didn't have a training loop in my script. I'm gonna work on incorporating that. Even though the last time I had one I know that I was running into issues with the library that I was using to have my model have a training loop. 
blockers: |
  Training loop might give me an issue on Colab since the last time I had one implemented I couldn't run my code due to library download issues on Colab, and I know when I removed it from my last algorithm I was able to get it to run. Hopefully, with this new algorith,m I can incorporate a training loop.

reflection: |
  Today felt a little bit slow. It started to speed up though Once I saw my check was available I went to pick it up. Finally paid, feeling like I could buy the whole earth lol. Also, I finally got my Code to compute on a much faster level once I was able to run my code on Gpu, I still have some things to fix though because all the loss values were low for epochs, I think my accuracy decreased by a little bit, I plan on looking at my code to see what I have to change in the parameters to get the accuracy back on pace for what it should be. 
---
